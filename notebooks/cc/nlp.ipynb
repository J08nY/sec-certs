{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# NLP??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from copy import deepcopy\n",
    "from sec_certs.dataset import CCDataset\n",
    "from sec_certs.utils.extract import load_text_file, flatten_matches\n",
    "from sec_certs.cert_rules import cc_rules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "default_tokenizer = deepcopy(nlp.tokenizer)\n",
    "dset = CCDataset.from_json(\"../../cc_dset/CommonCriteria_dataset.json\")\n",
    "#dset._extract_report_keywords(True)\n",
    "#dset._extract_targets_keywords(True)\n",
    "#dset._compute_normalized_cert_ids()\n",
    "#dset.to_json()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def customize_tokenizer(cert):\n",
    "    # The following groups of matches will be added to the default tokenizer as special rules (to not split them).\n",
    "    token_rule_groups = list(cc_rules.keys())\n",
    "    token_rule_groups.remove(\"certification_process\")\n",
    "    # Copy the default tokenizer\n",
    "    tokenizer = deepcopy(default_tokenizer)\n",
    "    for rule_group in token_rule_groups:\n",
    "        matches = set()\n",
    "        if cert.pdf_data.report_keywords:\n",
    "            matches.update(flatten_matches(cert.pdf_data.report_keywords[rule_group]).keys())\n",
    "        if cert.pdf_data.st_keywords:\n",
    "            matches.update(flatten_matches(cert.pdf_data.st_keywords[rule_group]).keys())\n",
    "        for match in matches:\n",
    "            tokenizer.add_special_case(match, [{\"ORTH\": match}])\n",
    "    tokenizer.add_special_case(\"re-certification\", [{\"ORTH\": \"re-certification\"}])\n",
    "    return tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cert = dset[\"05726637bd47a762\"]\n",
    "txt = load_text_file(cert.state.report_txt_path)[0]\n",
    "id_matches = set(flatten_matches(cert.pdf_data.report_keywords[\"cc_cert_id\"]).keys())\n",
    "print(cert.pdf_data.report_keywords[\"cc_cert_id\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp.tokenizer = customize_tokenizer(cert)\n",
    "doc = nlp(txt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sent = None\n",
    "for token in doc:\n",
    "    if token.text in id_matches:\n",
    "        if \"Certification Report\" in token.sent.text:\n",
    "            continue\n",
    "        print(token.sent)\n",
    "        for chunk in token.sent.noun_chunks:\n",
    "            print(\"-----\")\n",
    "            print(\"|\", chunk,  \"|\", spacy.explain(chunk.root.dep_), \"|\", chunk.root.head.text)\n",
    "        print(\"----------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sent = \"\"\"The underlying hardware platform, certified by BSI under reference BSI-DSZ-CC-1040 (BSI-DSZ-CC-\n",
    "1040-2019-MA-01), was re-evaluated by a different ITSEF while remaining under the same scheme\n",
    "but given a new reference, i.e. BSI-DSZ-CC-1136.\"\"\"\n",
    "sent = \"This is a re-certification based on BSI-DSZ-CC-1033-2019.\"\n",
    "sent = \"This evaluation is a re-evaluation of the certified OTA software 3AQ 21530 XAAA version 2.9 and hardware 3AQ 21564 AAAA ICS5A. Certification Report Identifier is SERTIT-003 CR, issue 1.0, 19.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}