{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current status of the notebook\n",
    "\n",
    "This notebook is meant for matching of CPE URIs to CC certificates and for subsequent matching of CVEs to the respective certificates. This is achieved as follows:\n",
    "\n",
    "- `JSONs` with CVE data are fetched from [nist.gov](https://nvd.nist.gov/vuln/data-feeds), relevant fields extracted and all data merged into single file. Functions `download_cve_data()` and `parse_all_cves()` take care of that. \n",
    "- `XML` file with [CPE records](https://nvd.nist.gov/products/cpe) is parsed to extract solely the title and CPE uri of all records. Functions ` get_cpe_uri_to_title_dict()`\n",
    "- CPE records are parsed into triplets `(vendor, product name, version)` and fetched into various dictionaries for `O(1)` access.\n",
    "- The `CommonCriteriaDataset` (see [GitHub repo](https://github.com/crocs-muni/sec-certs/blob/master/sec_certs/dataset.py)) is loaded as pandas dataframe\n",
    "- After some pre-processing, the function `match_cpe()` is called that based on the CC-certificate triplet `(vendor, certificate name, version)` attempts to find relevant CPE field, this is done as described below\n",
    "\n",
    "### Matching algorithm\n",
    "\n",
    "- First, the `vendor` goes through several heuristics and candidate vendors from the CPE-record database are found\n",
    "- Second, from the certificate, list of possible versions are extracted by regex matching. For instance, the string `IDOneClassIC Card : ID-One Cosmo 64 RSA v5.4 and applet IDOneClassIC v1.0 embedded on P5CT072VOP` will match possible versions `5.4` and `1.0`. Out of the cartesian product `candidate vendors x candidate versions`, list of existing pairs is found in the CPE database. \n",
    "- For each of the candidate `(vendor, version)` pairs, list of relevant CPE product names is retrieved.\n",
    "- Two fuzzy string matching algorithms are run against each of the candidate `cpe item`s and the certificate name. Best score out of all candidates is counted.\n",
    "- If no candidate with high-enough score was found (all `<60`), the requirement for version match is relaxed and the pair `(vendor, -)`, i.e. unknown version, is attempted. Stronger requirements are put on results produced by this branch.\n",
    "- All candidates with score `>70` and text length `>5` (otherwise it's easy to get high fuzzy-match score by accident) are considered promising.\n",
    "- The promising candidates are then to be manually checked by the analyst.\n",
    "\n",
    "### TODO\n",
    "\n",
    "There are multiple enhancmenents that can be done:\n",
    "\n",
    "- Better parsing of product versions\n",
    "- `1:n` matching, where some CC certificates have name like `McAfee Change Control and Application Control 8.3.0 with ePolicy Orchestrator 5.10.0` and CPE record exist both for `Change Control and Application Control 8.3.0` and for `ePolicy Orchestrator 5.10.0`\n",
    "- Vendor and version could be stripped while doing final fuzzy matching on `(cert name, cpe item)`\n",
    "- CPE titles could be used for matching instead of the `cpe item` field\n",
    "- The algorithm can be tuned to prefer more general version (for which the CVE will more likely apply)\n",
    "\n",
    "\n",
    "## Representativness of the acquired dataset\n",
    "\n",
    "In the bottom part of the notebook, several plots can be drawn to compare the feature distribution of the CPE-matched subset of CC dataset with the full CC dataset. The point is to rule-out a bias in the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Optional\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import requests\n",
    "import tempfile\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "sys.path.append('./..')\n",
    "import sec_certs.helpers as helpers\n",
    "\n",
    "tqdm.pandas()\n",
    "plt.style.use('seaborn')\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "pd.set_option(\"max_rows\", 100)\n",
    "\n",
    "replace_non_letter_non_numbers_with_space = re.compile(r\"(?ui)\\W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for CVE and CPE preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cve_data(output_dir: str, start_year=2002, end_year=2021):\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists:\n",
    "        output_dir.mkdir()\n",
    "\n",
    "    base_url = 'https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-'\n",
    "    urls = [base_url + str(x) + '.json.zip' for x in range(start_year, end_year + 1)]\n",
    "\n",
    "    print(f'Identified {len(urls)} CVE files to fetch from nist.gov. Downloading them into {output_dir}', flush=True)\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        outpaths = [Path(tmp_dir) / Path(x).name.rstrip('.zip') for x in urls]\n",
    "        responses = list(zip(*helpers.download_parallel(list(zip(urls, outpaths)), num_threads=8)))[1]\n",
    "\n",
    "        for o, u, r in zip(outpaths, urls, responses):\n",
    "            if r == 200:\n",
    "                with zipfile.ZipFile(o, 'r') as zip_handle:\n",
    "                    zip_handle.extractall(output_dir)\n",
    "            else:\n",
    "                print(f'Failed to download from {u}, got status code {r}')\n",
    "\n",
    "def parse_all_cves(cve_dir: str, output_path: str) -> None:\n",
    "    def get_relevant_info_from_file(input_path: Path) -> List[Dict]:\n",
    "        with input_path.open('r') as handle:\n",
    "            data = json.load(handle)\n",
    "        cve_data = []\n",
    "        for cve in data['CVE_Items']:\n",
    "            cve_data.append(get_relevant_info_from_cve(cve))\n",
    "        return cve_data\n",
    "    \n",
    "    def get_relevant_info_from_cve(cve: Dict) -> Dict:\n",
    "        cve_id = cve['cve']['CVE_data_meta']['ID']\n",
    "        impact = get_impact_from_cve(cve)\n",
    "        affected_cpes = get_affected_cpes_from_cve(cve)\n",
    "        return {'cve_id': cve_id, 'impact': impact, 'vulnerable_cpes': affected_cpes}\n",
    "\n",
    "    def get_impact_from_cve(cve: Dict) -> Dict:\n",
    "        result = {'base_score': None, 'severity': None, 'exploitabilityScore': None, 'impactScore': None}\n",
    "        if not cve['impact']:\n",
    "            pass\n",
    "        elif 'baseMetricV3' in cve['impact']:\n",
    "            result['base_score'] = cve['impact']['baseMetricV3']['cvssV3']['baseScore']\n",
    "            result['severity'] = cve['impact']['baseMetricV3']['cvssV3']['baseSeverity']\n",
    "            result['exploitabilityScore'] = cve['impact']['baseMetricV3']['exploitabilityScore']\n",
    "            result['impactScore'] = cve['impact']['baseMetricV3']['impactScore']\n",
    "        elif 'baseMetricV2' in cve['impact']:\n",
    "            result['base_score'] = cve['impact']['baseMetricV2']['cvssV2']['baseScore']\n",
    "            result['severity'] = cve['impact']['baseMetricV2']['severity']\n",
    "            result['exploitabilityScore'] = cve['impact']['baseMetricV2']['exploitabilityScore']\n",
    "            result['impactScore'] = cve['impact']['baseMetricV2']['impactScore']\n",
    "        return result\n",
    "    \n",
    "    def get_affected_cpes_from_cve(cve: Dict) -> List[str]:\n",
    "        affected_cpes = []\n",
    "        for node in cve['configurations']['nodes']:\n",
    "            affected_cpes.extend(get_affected_cpes_from_node(node))\n",
    "        return affected_cpes\n",
    "\n",
    "    def get_affected_cpes_from_node(node: Dict) -> List[str]:\n",
    "        cpe_uris = []\n",
    "        if 'children' in node:\n",
    "            for child in node['children']:\n",
    "                cpe_uris += get_affected_cpes_from_node(child)\n",
    "        if 'cpe_match' in node:\n",
    "            lst = node['cpe_match']\n",
    "            for x in lst:\n",
    "                if x['vulnerable']:\n",
    "                    cpe_uris.append(x['cpe23Uri'])\n",
    "        return cpe_uris\n",
    "\n",
    "\n",
    "    json_files = glob.glob(cve_dir + '/*.json')\n",
    "    print(f'Identified {len(json_files)} CVE files. Extracting relevant data and merging them into {output_path}', flush=True)\n",
    "    \n",
    "    all_cve_data = []\n",
    "    for filepath in tqdm(json_files):\n",
    "        all_cve_data.extend(get_relevant_info_from_file(Path(filepath)))\n",
    "\n",
    "    with open(output_path, 'w') as handle:\n",
    "        json.dump(all_cve_data, handle, indent=4)\n",
    "\n",
    "\n",
    "def get_cpe_uri_to_title_dict(input_xml_filepath: str, output_filepath: str):\n",
    "    print(f'Extracting dictionary cpe_uri:cpe_title from {input_xml_filepath} to {output_filepath}')\n",
    "    root = ET.parse(input_xml_filepath).getroot()\n",
    "    dct = {}\n",
    "    for cpe_item in root.findall('{http://cpe.mitre.org/dictionary/2.0}cpe-item'):\n",
    "        title = cpe_item.find('{http://cpe.mitre.org/dictionary/2.0}title').text\n",
    "        cpe_uri = cpe_item.find('{http://scap.nist.gov/schema/cpe-extension/2.3}cpe23-item').attrib['name']\n",
    "        dct[cpe_uri] = title\n",
    "    with open(output_filepath, 'w') as handle:\n",
    "        json.dump(dct, handle, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing realization and path specification\n",
    "\n",
    "Filepaths for rest of this notebook are specified here. Also, the realized three functions will:\n",
    "    \n",
    "1. Download all CVE datafiles\n",
    "2. Extract relevant CVE information from all files and merge it into single file\n",
    "3. Create a dictionary of `cpe_uri: cpe title`, will come handly later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVE_FOLDER_PATH = '/Users/adam/phd/projects/certificates/cpe_matching/new/cves'\n",
    "CVE_MERGED_FILEPATH = '/Users/adam/phd/projects/certificates/cpe_matching/new/cve_data.json'\n",
    "\n",
    "CPE_DICTIONARY_PATH = '/Users/adam/phd/projects/certificates/cpe_matching/new/cpe_dictionary.json'\n",
    "CPE_XML_PATH = '/Users/adam/phd/projects/certificates/cpe_matching/official-cpe-dictionary_v2.3.xml'\n",
    "\n",
    "PETR_ONE_TO_ONE_MATCH_JSON = '/Users/adam/Downloads/certs_to_cpe_single_match.json'\n",
    "CERTIFICATE_DATASET_CSV = '/Users/adam/phd/projects/certificates/cpe_matching/new/cc_full_dataset.csv'\n",
    "\n",
    "# download_cve_data(CVE_FOLDER_PATH)\n",
    "# parse_all_cves(CVE_FOLDER_PATH, CVE_MERGED_FILEPATH)\n",
    "# get_cpe_uri_to_title_dict(CPE_XML_PATH, CPE_DICTIONARY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions\n",
    "\n",
    "### CPE dictionary building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_cpe_vendor(cpe_record):\n",
    "    vendor = cpe_record.split(':')[3]\n",
    "    return ' '.join(vendor.split('_'))\n",
    "\n",
    "def get_cpe_product(cpe_record):\n",
    "    return ' '.join(cpe_record.split(':')[4].split('_'))\n",
    "\n",
    "def get_cpe_version(cpe_record):\n",
    "    return cpe_record.split(':')[5]\n",
    "\n",
    "with open(PETR_ONE_TO_ONE_MATCH_JSON, 'r') as handle:\n",
    "    petrs_matches = json.load(handle)\n",
    "petrs_matches = {x.split('.pdf')[0]:y for x,y in petrs_matches.items()}\n",
    "\n",
    "with open(CPE_DICTIONARY_PATH, 'r') as handle:\n",
    "    cpe_data = json.load(handle)\n",
    "\n",
    "cpe_triplets = [(get_cpe_vendor(x), get_cpe_product(x), get_cpe_version(x)) for x in cpe_data.keys()]\n",
    "cpe_uri_to_triplet = {x: (get_cpe_vendor(x), get_cpe_product(x), get_cpe_version(x)) for x in cpe_data.keys()}\n",
    "cpe_triplet_to_uri = {(get_cpe_vendor(x), get_cpe_product(x), get_cpe_version(x)): x for x in cpe_data.keys()}\n",
    "cpe_vendor_dict = {x: [] for x in [x[0] for x in cpe_triplets]}\n",
    "cpe_vendor_to_version_dict = {x: [] for x in [x[0] for x in cpe_triplets]}\n",
    "cpe_full_dict = {x: [] for x in [(x[0], x[2]) for x in cpe_triplets]}\n",
    "\n",
    "for vendor, product, version in cpe_triplets:\n",
    "    cpe_vendor_dict[vendor].append((vendor, product, version))\n",
    "    cpe_vendor_to_version_dict[vendor].append(version)\n",
    "    cpe_full_dict[(vendor, version)].append(product)\n",
    "    \n",
    "with open(CVE_MERGED_FILEPATH, 'r') as handle:\n",
    "    cve_dataset = json.load(handle)\n",
    "vuln_score_mapping = {x['cve_id']: x['impact']['base_score'] for x in cve_dataset}\n",
    "\n",
    "def get_cve_ids_for_cpe_uri(cpe_uri):\n",
    "    if not isinstance(cpe_uri, str):\n",
    "        return None\n",
    "    if not (ids := [cve['cve_id'] for cve in cve_dataset if cpe_uri in cve['vulnerable_cpes']]):\n",
    "        return None\n",
    "    else:\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual functions for CPE<->Certificate matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_cert_version(crt_name):\n",
    "    at_least_something = r'(\\b(\\d)+\\b)'\n",
    "    just_numbers = r'(\\d{1,5})(\\.\\d{1,5})'\n",
    "    \n",
    "    without_version = r'(' + just_numbers + r'+)'\n",
    "    long_version = r'(' + r'(\\bversion)\\s*' + just_numbers + r'+)'\n",
    "    short_version = r'(' + r'\\bv\\s*' + just_numbers + r'+)'\n",
    "    full_regex_string = r'|'.join([without_version, short_version, long_version])\n",
    "    normalizer = r'(\\d+\\.*)+'\n",
    "\n",
    "    matched_strings = set([max(x, key=len) for x in re.findall(full_regex_string, crt_name, re.IGNORECASE)])\n",
    "    if not matched_strings:\n",
    "        matched_strings = set([max(x, key=len) for x in re.findall(at_least_something, crt_name, re.IGNORECASE)])\n",
    "\n",
    "    if matched_strings:\n",
    "        return [re.search(normalizer, x).group() for x in matched_strings]\n",
    "    else:\n",
    "        return ['-']\n",
    "    \n",
    "\n",
    "\n",
    "def map_petrs_match(report_link):\n",
    "    for x in petrs_matches.keys():\n",
    "        if x.replace(' ', '%20') in report_link:\n",
    "            base_string = 'hotfix:' + petrs_matches[x]\n",
    "            return get_cpe_vendor(base_string), get_cpe_product(base_string), get_cpe_version(base_string)\n",
    "    return None\n",
    "\n",
    "def get_matching_vendors(vendor_name: str) -> Optional[List[str]]:\n",
    "    result = set()\n",
    "    if not isinstance(vendor_name, str):\n",
    "        return None\n",
    "    lower = vendor_name.lower()\n",
    "    if ' / ' in vendor_name:\n",
    "        chain = [get_matching_vendors(x) for x in vendor_name.split(' / ')]\n",
    "        chain = [x for x in chain if x]\n",
    "        return list(set(itertools.chain(*chain)))\n",
    "    if lower in cpe_vendor_dict.keys():\n",
    "        result.add(lower)\n",
    "    if ' ' in lower and (y := lower.split(' ')[0]) in cpe_vendor_dict.keys():\n",
    "        result.add(y)\n",
    "    if ',' in lower and (y := lower.split(',')[0]) in cpe_vendor_dict.keys():\n",
    "        result.add(y)\n",
    "    if not result:\n",
    "        return None\n",
    "    return list(result)\n",
    "\n",
    "def get_matching_versions(cert_versions: List[str], vendor_candidates: List[str]):\n",
    "    just_numbers = r'(\\d{1,5})(\\.\\d{1,5})'\n",
    "    matching_versions = set()\n",
    "    for v in vendor_candidates:\n",
    "        for c in cert_versions:\n",
    "            if (c.startswith(v) and re.search(just_numbers, v)) or v.startswith(c):\n",
    "                matching_versions.add(v)\n",
    "    return list(matching_versions)\n",
    "\n",
    "def get_best_match(cert_name: str, list_of_pairs: List[Tuple[str, str]]):\n",
    "    def sanitize_matched_string(string):\n",
    "        string = string.replace('®', '').replace('™', '').lower()\n",
    "        return replace_non_letter_non_numbers_with_space.sub(' ', string)\n",
    "\n",
    "    best_match = 0\n",
    "    best_candidate = (None, None, None)\n",
    "    if not list_of_pairs:\n",
    "        return best_match, best_candidate\n",
    "\n",
    "    for vendor, version in list_of_pairs:\n",
    "        for candidate in cpe_full_dict[(vendor, version)]:\n",
    "            sanitized_cert_name = sanitize_matched_string(cert_name)\n",
    "            sanitized_candidate = sanitize_matched_string(candidate)\n",
    "            potential = max(fuzz.token_set_ratio(sanitized_cert_name, sanitized_candidate), fuzz.partial_ratio(sanitized_cert_name, sanitized_candidate))\n",
    "            if (potential - best_match) > 1 or \\\n",
    "               (best_candidate[1] and len(best_candidate[1]) > 10 and abs(potential - best_match) < 1 and best_candidate[2] and len(version) < len(best_candidate[2])) or \\\n",
    "               (abs(potential - best_match) < 1 and best_candidate[0] and len(candidate) > len(best_candidate[1])):\n",
    "                    best_match = potential\n",
    "                    best_candidate = vendor, candidate, version\n",
    "    return best_match, best_candidate\n",
    "\n",
    "\n",
    "def match_cpe(vendor_name: str, cert_name: str, versions: List[str]):\n",
    "    matching_vendors = get_matching_vendors(vendor_name)\n",
    "    matching_versions = []\n",
    "    if not matching_vendors:\n",
    "        return None, None\n",
    "\n",
    "    all_candidates = []\n",
    "\n",
    "    for v in matching_vendors:\n",
    "        matching_versions.append(get_matching_versions(versions, cpe_vendor_to_version_dict[v]))\n",
    "\n",
    "    for vendor, versions in zip(matching_vendors, matching_versions):\n",
    "        all_candidates.extend((vendor, v) for v in versions)\n",
    "\n",
    "    best_match, best_candidate = get_best_match(cert_name, all_candidates)\n",
    "\n",
    "    # If we didn't get anything meaningful, try to relax the version and return only if long match and extra certain\n",
    "    if best_match < 60:\n",
    "        alt_candidates = [(v, '-') for v in matching_vendors if '-' in cpe_vendor_to_version_dict[v]]\n",
    "        alt_best_match, alt_best_candidate = get_best_match(cert_name, alt_candidates)\n",
    "        if alt_best_candidate[1] and len(alt_best_candidate[1]) > 5 and alt_best_match > 70:\n",
    "            return alt_best_match, alt_best_candidate\n",
    "    \n",
    "    return best_match, best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sec_level_dict = {'EAL1': 0, 'EAL1+': 1, 'EAL2': 2, 'EAL2+': 3, 'EAL3': 4, 'EAL3+': 5, 'EAL4': 6, 'EAL4+': 7, 'EAL5': 8, 'EAL5+': 9, 'EAL6': 10, 'EAL6+': 11, 'EAL7': 12, 'EAL7+': 13}\n",
    "\n",
    "df = pd.read_csv(CERTIFICATE_DATASET_CSV, sep=';')\n",
    "df = df.set_index('dgst')\n",
    "\n",
    "df.security_level = df.security_level.map(ast.literal_eval) # Since we have it in string representation, not needed when deserializing\n",
    "\n",
    "df['max_security_level'] = df.security_level.map(lambda x: max([sec_level_dict.get(y, -1) for y in x]) if x else -1)\n",
    "\n",
    "df['version'] = df['name'].map(parse_cert_version)\n",
    "\n",
    "df.not_valid_before = df.not_valid_before.apply(pd.to_datetime)\n",
    "df.not_valid_after = df.not_valid_after.apply(pd.to_datetime)\n",
    "\n",
    "df['petr_match'] = df.report_link.map(map_petrs_match)\n",
    "df['adam_match'] = df.apply(lambda x: match_cpe(x['manufacturer'], x['name'], x['version']), axis=1)\n",
    "\n",
    "df['match_score'] = df.adam_match.apply(lambda x: x[0])\n",
    "df['adam_match'] = df.adam_match.apply(lambda x: x[1])\n",
    "\n",
    "df['has_long_cpe_match'] = df.adam_match.apply(lambda x: len(x[1]) > 5 if x and x[1] else False)\n",
    "df['matched_cpe_uri'] = df.adam_match.map(cpe_triplet_to_uri)\n",
    "\n",
    "df_full = df.copy()\n",
    "\n",
    "# # Filter only to relevant pieces\n",
    "\n",
    "df = df.loc[df.has_long_cpe_match == True]\n",
    "df = df.loc[df.match_score > 80]\n",
    "\n",
    "df['related_cves'] = df.matched_cpe_uri.progress_map(get_cve_ids_for_cpe_uri)\n",
    "df['n_related_cves'] = df.related_cves.apply(lambda x: len(x) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cves = df.explode('related_cves')\n",
    "df_cves = df_cves.reset_index()\n",
    "df_cves['cve_score'] = df_cves.related_cves.map(vuln_score_mapping)\n",
    "df_cves = df_cves.loc[df_cves.n_related_cves < 100]\n",
    "df_cves = df_cves.loc[df_cves.max_security_level > -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distribution of years in All vs CPE-rich certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_matched = df.not_valid_before.dt.year.value_counts().sort_index().rename('# all certificates')\n",
    "years_all = df_full.not_valid_before.dt.year.value_counts().sort_index().rename('# CPE-rich certificates')\n",
    "years_merged = pd.concat([years_all, years_matched], axis=1)\n",
    "years_merged = years_merged.fillna(0)\n",
    "years_merged = years_merged.div(years_merged.sum(axis=0), axis=1)\n",
    "ax = years_merged.plot(title='Proportion of certificates not-valid-before given year')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('/Users/adam/Downloads/n_certs.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare distribution of categories between all vs CPE-rich certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_filtered = df.category.value_counts().sort_index().rename('Category distribution CPE-rich')\n",
    "categories_all = df_full.category.value_counts().sort_index().rename('Category distribution all')\n",
    "categories_merged = pd.concat([categories_filtered, categories_all], axis=1)\n",
    "categories_merged = categories_merged.drop('ICs, Smart Cards and Smart Card-Related Devices and Systems')\n",
    "categories_merged = categories_merged.div(categories_merged.sum(axis=0), axis=1)\n",
    "ax = categories_merged.plot.bar(title='Categories (without smartcards) comparison between CPE-rich and all certificates')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('/Users/adam/Downloads/categories.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare distribution of EAL levels between all vs CPE-rich certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_filtered = df.max_security_level.value_counts().sort_index().rename('Sec. level distribution CPE-rich')\n",
    "levels_all = df_full.max_security_level.value_counts().sort_index().rename('Sec. level distribution all')\n",
    "levels_merged = pd.concat([levels_filtered, levels_all],  axis=1)\n",
    "levels_merged = levels_merged.fillna(0)\n",
    "levels_merged = levels_merged.div(levels_merged.sum(axis=0), axis=1)\n",
    "ax = levels_merged.plot.bar(title='Security levels in CPE-rich certificate vs all certificates')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('/Users/adam/Downloads/security_levels.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cves.plot.hexbin(x='max_security_level',\n",
    "                    y='cve_score',\n",
    "                    gridsize=20,\n",
    "                    colormap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = df_cves.plot.scatter('max_security_level', 'cve_score', c='n_related_cves', colormap='viridis',\n",
    "                         s = 40,\n",
    "                         title='CVE score vs. security level of affected certificate. Color = number of CVEs related to certificate',\n",
    "                         xlabel='Security level, EAL1=0, EAL7+=13',\n",
    "                         ylabel='CVE severity score 1-10',\n",
    "                         figsize=(12,10), ax=ax)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('/Users/adam/Downloads/scatter_plot.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between Adam's and Petr's matching\n",
    "interesting_cols = ['name', 'manufacturer', 'version', 'match_score', 'adam_match', 'petr_match']\n",
    "df_diff = df_full.loc[(df_full.petr_match.notnull()) & (df_full.petr_match != df_full.adam_match), interesting_cols]\n",
    "df_diff[interesting_cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cert-venv",
   "language": "python",
   "name": "cert-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}