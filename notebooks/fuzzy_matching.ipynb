{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Optional\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import requests\n",
    "import tempfile\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "sys.path.append('./..')\n",
    "import sec_certs.helpers as helpers\n",
    "\n",
    "tqdm.pandas()\n",
    "plt.style.use('seaborn')\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "pd.set_option(\"max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for CVE and CPE preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cve_data(output_dir: str, start_year=2002, end_year=2021):\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists:\n",
    "        output_dir.mkdir()\n",
    "\n",
    "    base_url = 'https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-'\n",
    "    urls = [base_url + str(x) + '.json.zip' for x in range(start_year, end_year + 1)]\n",
    "\n",
    "    print(f'Identified {len(urls)} CVE files to fetch from nist.gov. Downloading them into {output_dir}', flush=True)\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        outpaths = [Path(tmp_dir) / Path(x).name.rstrip('.zip') for x in urls]\n",
    "        responses = list(zip(*helpers.download_parallel(list(zip(urls, outpaths)), num_threads=8)))[1]\n",
    "\n",
    "        for o, u, r in zip(outpaths, urls, responses):\n",
    "            if r == 200:\n",
    "                with zipfile.ZipFile(o, 'r') as zip_handle:\n",
    "                    zip_handle.extractall(output_dir)\n",
    "            else:\n",
    "                print(f'Failed to download from {u}, got status code {r}')\n",
    "\n",
    "def parse_all_cves(cve_dir: str, output_path: str) -> None:\n",
    "    def get_relevant_info_from_file(input_path: Path) -> List[Dict]:\n",
    "        with input_path.open('r') as handle:\n",
    "            data = json.load(handle)\n",
    "        cve_data = []\n",
    "        for cve in data['CVE_Items']:\n",
    "            cve_data.append(get_relevant_info_from_cve(cve))\n",
    "        return cve_data\n",
    "    \n",
    "    def get_relevant_info_from_cve(cve: Dict) -> Dict:\n",
    "        cve_id = cve['cve']['CVE_data_meta']['ID']\n",
    "        impact = get_impact_from_cve(cve)\n",
    "        affected_cpes = get_affected_cpes_from_cve(cve)\n",
    "        return {'cve_id': cve_id, 'impact': impact, 'vulnerable_cpes': affected_cpes}\n",
    "\n",
    "    def get_impact_from_cve(cve: Dict) -> Dict:\n",
    "        result = {'base_score': None, 'severity': None, 'exploitabilityScore': None, 'impactScore': None}\n",
    "        if not cve['impact']:\n",
    "            pass\n",
    "        elif 'baseMetricV3' in cve['impact']:\n",
    "            result['base_score'] = cve['impact']['baseMetricV3']['cvssV3']['baseScore']\n",
    "            result['severity'] = cve['impact']['baseMetricV3']['cvssV3']['baseSeverity']\n",
    "            result['exploitabilityScore'] = cve['impact']['baseMetricV3']['exploitabilityScore']\n",
    "            result['impactScore'] = cve['impact']['baseMetricV3']['impactScore']\n",
    "        elif 'baseMetricV2' in cve['impact']:\n",
    "            result['base_score'] = cve['impact']['baseMetricV2']['cvssV2']['baseScore']\n",
    "            result['severity'] = cve['impact']['baseMetricV2']['severity']\n",
    "            result['exploitabilityScore'] = cve['impact']['baseMetricV2']['exploitabilityScore']\n",
    "            result['impactScore'] = cve['impact']['baseMetricV2']['impactScore']\n",
    "        return result\n",
    "    \n",
    "    def get_affected_cpes_from_cve(cve: Dict) -> List[str]:\n",
    "        affected_cpes = []\n",
    "        for node in cve['configurations']['nodes']:\n",
    "            affected_cpes.extend(get_affected_cpes_from_node(node))\n",
    "        return affected_cpes\n",
    "\n",
    "    def get_affected_cpes_from_node(node: Dict) -> List[str]:\n",
    "        cpe_uris = []\n",
    "        if 'children' in node:\n",
    "            for child in node['children']:\n",
    "                cpe_uris += get_affected_cpes_from_node(child)\n",
    "        if 'cpe_match' in node:\n",
    "            lst = node['cpe_match']\n",
    "            for x in lst:\n",
    "                if x['vulnerable']:\n",
    "                    cpe_uris.append(x['cpe23Uri'])\n",
    "        return cpe_uris\n",
    "\n",
    "\n",
    "    json_files = glob.glob(cve_dir + '/*.json')\n",
    "    print(f'Identified {len(json_files)} CVE files. Extracting relevant data and merging them into {output_path}', flush=True)\n",
    "    \n",
    "    all_cve_data = []\n",
    "    for filepath in tqdm(json_files):\n",
    "        all_cve_data.extend(get_relevant_info_from_file(Path(filepath)))\n",
    "\n",
    "    with open(output_path, 'w') as handle:\n",
    "        json.dump(all_cve_data, handle, indent=4)\n",
    "\n",
    "\n",
    "def get_cpe_uri_to_title_dict(input_xml_filepath: str, output_filepath: str):\n",
    "    print(f'Extracting dictionary cpe_uri:cpe_title from {input_xml_filepath} to {output_filepath}')\n",
    "    root = ET.parse(input_xml_filepath).getroot()\n",
    "    dct = {}\n",
    "    for cpe_item in root.findall('{http://cpe.mitre.org/dictionary/2.0}cpe-item'):\n",
    "        title = cpe_item.find('{http://cpe.mitre.org/dictionary/2.0}title').text\n",
    "        cpe_uri = cpe_item.find('{http://scap.nist.gov/schema/cpe-extension/2.3}cpe23-item').attrib['name']\n",
    "        dct[cpe_uri] = title\n",
    "    with open(output_filepath, 'w') as handle:\n",
    "        json.dump(dct, handle, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing realization and path specification\n",
    "\n",
    "Filepaths for rest of this notebook are specified here. Also, the realized three functions will:\n",
    "    \n",
    "1. Download all CVE datafiles\n",
    "2. Extract relevant CVE information from all files and merge it into single file\n",
    "3. Create a dictionary of `cpe_uri: cpe title`, will come handly later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVE_FOLDER_PATH = '/Users/adam/phd/projects/certificates/cpe_matching/new/cves'\n",
    "CVE_MERGED_FILEPATH = '/Users/adam/phd/projects/certificates/cpe_matching/new/cve_data.json'\n",
    "\n",
    "CPE_DICTIONARY_PATH = '/Users/adam/phd/projects/certificates/cpe_matching/new/cpe_dictionary.json'\n",
    "CPE_XML_PATH = '/Users/adam/phd/projects/certificates/cpe_matching/official-cpe-dictionary_v2.3.xml'\n",
    "\n",
    "PETR_ONE_TO_ONE_MATCH_JSON = '/Users/adam/Downloads/certs_to_cpe_single_match.json'\n",
    "CERTIFICATE_DATASET_CSV = '/Users/adam/phd/projects/certificates/cpe_matching/new/cc_full_dataset.csv'\n",
    "\n",
    "download_cve_data(CVE_FOLDER_PATH)\n",
    "parse_all_cves(CVE_FOLDER_PATH, CVE_MERGED_FILEPATH)\n",
    "get_cpe_uri_to_title_dict(CPE_XML_PATH, CPE_DICTIONARY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions\n",
    "\n",
    "### CPE dictionary building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_cpe_vendor(cpe_record):\n",
    "    vendor = cpe_record.split(':')[3]\n",
    "    return ' '.join(vendor.split('_'))\n",
    "\n",
    "def get_cpe_product(cpe_record):\n",
    "    return ' '.join(cpe_record.split(':')[4].split('_'))\n",
    "\n",
    "def get_cpe_version(cpe_record):\n",
    "    return cpe_record.split(':')[5]\n",
    "\n",
    "with open(PETR_ONE_TO_ONE_MATCH_JSON, 'r') as handle:\n",
    "    petrs_matches = json.load(handle)\n",
    "petrs_matches = {x.split('.pdf')[0]:y for x,y in petrs_matches.items()}\n",
    "\n",
    "with open(CPE_DICTIONARY_PATH, 'r') as handle:\n",
    "    cpe_data = json.load(handle)\n",
    "\n",
    "cpe_triplets = [(get_cpe_vendor(x), get_cpe_product(x), get_cpe_version(x)) for x in cpe_data.keys()]\n",
    "cpe_uri_to_triplet = {x: (get_cpe_vendor(x), get_cpe_product(x), get_cpe_version(x)) for x in cpe_data.keys()}\n",
    "cpe_triplet_to_uri = {(get_cpe_vendor(x), get_cpe_product(x), get_cpe_version(x)): x for x in cpe_data.keys()}\n",
    "cpe_vendor_dict = {x: [] for x in [x[0] for x in cpe_triplets]}\n",
    "cpe_vendor_to_version_dict = {x: [] for x in [x[0] for x in cpe_triplets]}\n",
    "cpe_full_dict = {x: [] for x in [(x[0], x[2]) for x in cpe_triplets]}\n",
    "\n",
    "for vendor, product, version in cpe_triplets:\n",
    "    cpe_vendor_dict[vendor].append((vendor, product, version))\n",
    "    cpe_vendor_to_version_dict[vendor].append(version)\n",
    "    cpe_full_dict[(vendor, version)].append(product)\n",
    "    \n",
    "with open(CVE_MERGED_FILEPATH, 'r') as handle:\n",
    "    cve_dataset = json.load(handle)\n",
    "vuln_score_mapping = {x['cve_id']: x['impact']['base_score'] for x in cve_dataset}\n",
    "\n",
    "def get_cve_ids_for_cpe_uri(cpe_uri):\n",
    "    if not isinstance(cpe_uri, str):\n",
    "        return None\n",
    "    if not (ids := [cve['cve_id'] for cve in cve_dataset if cpe_uri in cve['vulnerable_cpes']]):\n",
    "        return None\n",
    "    else:\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual functions for CPE<->Certificate matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_cert_version(crt_name):\n",
    "    # TODO: E.g. Huawei with version V100R005C30SPC300 gets parsed as 300\n",
    "    # TODO: Enhance version capabilities\n",
    "    just_numbers = r'(\\d{1,5})(\\.\\d{1,5})'\n",
    "\n",
    "    without_version = just_numbers + '+'\n",
    "    long_version = r'(\\bversion)\\s*' + just_numbers + '*'\n",
    "    short_version = r'\\bv\\s*' + just_numbers + '*'\n",
    "    regexps = [without_version, long_version, short_version]\n",
    "\n",
    "    true_matches = [re.search(x, crt_name, re.IGNORECASE) for x in regexps]\n",
    "    true_matches = [x for x in true_matches if x is not None]\n",
    "    if true_matches:\n",
    "        first_match = true_matches[0].group()\n",
    "        return re.search(just_numbers + r'*', first_match, re.IGNORECASE).group()\n",
    "    return '-'\n",
    "\n",
    "def map_petrs_match(report_link):\n",
    "    for x in petrs_matches.keys():\n",
    "        if x.replace(' ', '%20') in report_link:\n",
    "            base_string = 'hotfix:' + petrs_matches[x]\n",
    "            return get_cpe_vendor(base_string), get_cpe_version(base_string), get_cpe_product(base_string)\n",
    "    return None\n",
    "\n",
    "def get_matching_vendors(vendor_name: str) -> Optional[List[str]]:\n",
    "    result = set()\n",
    "    if not isinstance(vendor_name, str):\n",
    "        return None\n",
    "    lower = vendor_name.lower()\n",
    "    if ' / ' in vendor_name:\n",
    "        chain = [get_matching_vendors(x) for x in vendor_name.split(' / ')]\n",
    "        chain = [x for x in chain if x]\n",
    "        return list(set(itertools.chain(*chain)))\n",
    "    if lower in cpe_vendor_dict.keys():\n",
    "        result.add(lower)\n",
    "    if ' ' in lower and (y := lower.split(' ')[0]) in cpe_vendor_dict.keys():\n",
    "        result.add(y)\n",
    "    if ',' in lower and (y := lower.split(',')[0]) in cpe_vendor_dict.keys():\n",
    "        result.add(y)\n",
    "    if not result:\n",
    "        return None\n",
    "    return list(result)\n",
    "\n",
    "def get_matching_versions(my_version: str, candidates: List[str]):\n",
    "    just_numbers = r'(\\d{1,5})(\\.\\d{1,5})'\n",
    "    return list({x for x in candidates if ((my_version.startswith(x) and re.search(just_numbers, x)) or x.startswith(my_version))})\n",
    "\n",
    "def get_best_match(cert_name: str, list_of_pairs: List[Tuple[str, str]]):\n",
    "    # TODO: If equal matches, this kind of returns random match\n",
    "    best_match = 0\n",
    "    best_candidate = (None, None, None)\n",
    "    if not list_of_pairs:\n",
    "        return best_match, best_candidate\n",
    "\n",
    "    for vendor, version in list_of_pairs:\n",
    "        for candidate in cpe_full_dict[(vendor, version)]:\n",
    "            if (potential := fuzz.partial_ratio(cert_name, candidate)) > best_match:\n",
    "                best_match = potential\n",
    "                best_candidate = vendor, candidate, version\n",
    "    return best_match, best_candidate\n",
    "\n",
    "\n",
    "def match_cpe(vendor_name: str, cert_name: str, version: str):\n",
    "    matching_vendors = get_matching_vendors(vendor_name)\n",
    "    matching_versions = []\n",
    "    if not matching_vendors:\n",
    "        return None, None\n",
    "\n",
    "    all_candidates = []\n",
    "\n",
    "    for v in matching_vendors:\n",
    "        matching_versions.append(get_matching_versions(version, cpe_vendor_to_version_dict[v]))\n",
    "\n",
    "    for vendor, versions in zip(matching_vendors, matching_versions):\n",
    "        all_candidates.extend([vendor, v] for v in versions)\n",
    "\n",
    "    best_match, best_candidate = get_best_match(cert_name, all_candidates)\n",
    "    return best_match, best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sec_level_dict = {'EAL1': 0, 'EAL1+': 1, 'EAL2': 2, 'EAL2+': 3, 'EAL3': 4, 'EAL3+': 5, 'EAL4': 6, 'EAL4+': 7, 'EAL5': 8, 'EAL5+': 9, 'EAL6': 10, 'EAL6+': 11, 'EAL7': 12, 'EAL7+': 13}\n",
    "\n",
    "df = pd.read_csv(CERTIFICATE_DATASET_CSV, sep=';')\n",
    "df = df.set_index('dgst')\n",
    "\n",
    "df.security_level = df.security_level.map(ast.literal_eval) # Since we have it in string representation, not needed when deserializing\n",
    "\n",
    "df['max_security_level'] = df.security_level.map(lambda x: max([sec_level_dict.get(y, -1) for y in x]) if x else -1)\n",
    "\n",
    "df['version'] = df['name'].map(parse_cert_version)\n",
    "\n",
    "df.not_valid_before = df.not_valid_before.apply(pd.to_datetime)\n",
    "df.not_valid_after = df.not_valid_after.apply(pd.to_datetime)\n",
    "\n",
    "df['petr_match'] = df.report_link.map(map_petrs_match)\n",
    "df['adam_match'] = df.apply(lambda x: match_cpe(x['manufacturer'], x['name'], x['version']), axis=1)\n",
    "\n",
    "df['match_score'] = df.adam_match.apply(lambda x: x[0])\n",
    "df['adam_match'] = df.adam_match.apply(lambda x: x[1])\n",
    "\n",
    "df['has_long_cpe_match'] = df.adam_match.apply(lambda x: len(x[1]) > 5 if x and x[1] else False)\n",
    "df['matched_cpe_uri'] = df.adam_match.map(cpe_triplet_to_uri)\n",
    "\n",
    "# # Filter only to relevant pieces\n",
    "df = df.loc[df.has_long_cpe_match == True]\n",
    "df = df.loc[df.match_score > 80]\n",
    "\n",
    "df['related_cves'] = df.matched_cpe_uri.progress_map(get_cve_ids_for_cpe_uri)\n",
    "df['n_related_cves'] = df.related_cves.apply(lambda x: len(x) if x else 0)\n",
    "\n",
    "# df_vuln = df.loc[df.n_related_cves > 0 ]\n",
    "# vulnerable_certs_dict = df_vuln.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cves = df.explode('related_cves')\n",
    "df_cves = df_cves.reset_index()\n",
    "df_cves['cve_score'] = df_cves.related_cves.map(vuln_score_mapping)\n",
    "df_cves = df_cves.loc[df_cves.n_related_cves < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = df_cves.plot.scatter('max_security_level', 'cve_score', c='n_related_cves', colormap='viridis',\n",
    "                         s = 40,\n",
    "                         title='CVE score vs. security level of affected certificate. Color = number of CVEs related to certificate',\n",
    "                         xlabel='Security level, EAL1=0, EAL7+=13',\n",
    "                         ylabel='CVE severity score 1-10',\n",
    "                         figsize=(12,10), ax=ax)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('/Users/adam/Downloads/scatter_plot.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cert-venv",
   "language": "python",
   "name": "cert-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}