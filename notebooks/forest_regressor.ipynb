{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/adam/phd/projects/certificates/data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(importances, feature_names):\n",
    "    importances, feature_names = zip(*sorted(zip(importances, feature_names), reverse=True))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(feature_names, importances)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title('Feature importance in Random Forest classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load json features into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all features and fill a dataframe with them\n",
    "feature_dict = {x: [] for x in ['category', 'scheme', 'n_updates', 'sec_level_processed', 'cert_lab', 'n_pages',\n",
    "                           'cert_date', 'archived_date', 'manufacturer', 'protection_profiles', 'pdf_encrypted', 'defenses', 'crypto_algs']}\n",
    "for key, val in data.items():\n",
    "    cert = data[key]\n",
    "    feature_dict['category'].append(cert['csv_scan'].get('cc_category', np.nan))\n",
    "    feature_dict['scheme'].append(cert['csv_scan'].get('cc_scheme', np.nan))\n",
    "    feature_dict['n_updates'].append(len(cert['csv_scan'].get('maintainance_updates', np.nan)))\n",
    "    feature_dict['sec_level_processed'].append(cert['processed'].get('cc_security_level', np.nan))\n",
    "    feature_dict['cert_lab'].append(cert['processed'].get('cert_lab', np.nan))\n",
    "    feature_dict['cert_date'].append(cert['csv_scan'].get('cc_certification_date', np.nan))\n",
    "    feature_dict['archived_date'].append(cert['csv_scan'].get('cc_archived_date', np.nan))\n",
    "    feature_dict['manufacturer'].append(cert['processed'].get('cc_manufacturer_simple', np.nan))\n",
    "    feature_dict['protection_profiles'].append(cert['csv_scan'].get('cc_protection_profiles', np.nan))\n",
    "\n",
    "    keywords_scan = cert.get('keywords_scan') or {}\n",
    "    feature_dict['defenses'].append(keywords_scan.get('rules_defenses', np.nan))\n",
    "    feature_dict['crypto_algs'].append(keywords_scan.get('rules_crypto_algs', np.nan))\n",
    "    \n",
    "    \n",
    "    meta_scan = cert.get('pdfmeta_scan') or {}\n",
    "    n_pages = meta_scan.get('pdf_number_of_pages', np.nan)\n",
    "    pdf_encrypted = meta_scan.get('pdf_is_encrypted', np.nan)\n",
    "    feature_dict['n_pages'].append(n_pages)\n",
    "    feature_dict['pdf_encrypted'].append(pdf_encrypted)\n",
    "df = pd.DataFrame(data=feature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature description\n",
    "\n",
    "| Feature name | Feature type | N. unique val. | N. missing | notes |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| category | nominal | 15 | 0 | - |\n",
    "| scheme | nominal | 17 | 0 | 8 prevalent, merge below 100? |\n",
    "| n_updates | ordinal | 12 | 0 | set intervals [0,0), (1,1], (2,2], (3, inf) |\n",
    "| sec_level_processed | ordinal | 14 | 0 | + stands for additional defenses |\n",
    "| cert_lab | nominal | 13 | 2740 | Could be very useful, need to get more |\n",
    "| n_pages | numerical | - | 923 | Split into categories by histogram | \n",
    "| cert_date | Date | - | 0 | |\n",
    "| archived_date | Date | - | 0 | Beware of huge number of archived in Sep. 2019|\n",
    "| manufacturer | nominal | 807 | 10 | Need to merge if it should be of some use |\n",
    "| protection_profiles | nominal | 216 | 0 (or 2300)| Take length of list as feature |\n",
    "| pdf_encrypted | boolean | True/False | 674 | If missing set false |\n",
    "| defenses | nominal | - | 668 | To be processed to number of keys |\n",
    "| crypto_algs | nominal | - | 668 | To be processed to number of algs. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of missing values per each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pdf_encrypted.fillna(False, inplace=True)\n",
    "df.defenses = df.defenses.map(lambda x: {} if pd.isnull(x) else x)\n",
    "df.crypto_algs = df.crypto_algs.map(lambda x: {} if pd.isnull(x) else x)\n",
    "\n",
    "n_pages_median = df.n_pages.median()\n",
    "df.n_pages.fillna(n_pages_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize nominal and ordinal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map defenses and crypto algs to the length of the list\n",
    "map_to_len = lambda x: len(x) if isinstance(x, dict) else 0\n",
    "df['n_defenses'] = df.defenses.map(map_to_len)\n",
    "df['n_crypto_algs'] = df.crypto_algs.map(map_to_len)\n",
    "\n",
    "# map protection profiles to the length of the list\n",
    "prot_prof_to_len = lambda x: len(x.split(',')) if x != '' else 0\n",
    "df['n_protection_profiles'] = df.protection_profiles.map(prot_prof_to_len)\n",
    "\n",
    "# Map security level into ordered categories\n",
    "sec_level_dict = {'None': np.nan, 'EAL1': 0, 'EAL1+': 1, 'EAL2': 2, 'EAL2+': 3, 'EAL3': 4, 'EAL3+': 4, 'EAL4': 5, 'EAL4+': 6, 'EAL5': 7, 'EAL5+': 8, 'EAL6': 9, 'EAL6+': 10, 'EAL7': 11, 'EAL7+': 12}\n",
    "df['sec_level_cat'] = df.sec_level_processed.map(sec_level_dict)\n",
    "sec_level_median = df['sec_level_cat'].loc[df.sec_level_cat != -1].median()\n",
    "df['sec_level_cat'].fillna(sec_level_median, inplace=True)\n",
    "\n",
    "# categorize n_pages into intervals (ordered)\n",
    "df['n_pages_cat'] = pd.cut(df.n_pages, [0, 10, 15, 30, 40, 50, 5000], labels=[x for x in range(6)])\n",
    "df.n_pages_cat = df['n_pages_cat'].astype('int64')\n",
    "\n",
    "# Categories number of updates to intervals\n",
    "df['n_updates_cat'] = pd.cut(df.n_updates, [-1, 0, 1, 2, 3, 100], labels=[x for x in range(5)])\n",
    "df['n_updates_cat'] = df['n_updates_cat'].astype('int64')\n",
    "\n",
    "# Create year of certification feature\n",
    "df.cert_date = pd.to_datetime(df.cert_date)\n",
    "df.archived_date = pd.to_datetime(df.archived_date)\n",
    "df['cert_year'] = df.cert_date.dt.year\n",
    "\n",
    "# Categorize schemes, not sure if wise\n",
    "n_occurences = df.scheme.value_counts()\n",
    "schemes_to_merge = list(n_occurences.loc[n_occurences < 100].index)\n",
    "df['scheme_cat'] = df.scheme.map(lambda x: x if x not in schemes_to_merge else 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histogram\n",
    "%matplotlib inline\n",
    "df.hist(bins=20, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show correlations between numerical features and the target feature\n",
    "df.corr()['sec_level_cat'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, ['category', 'n_updates', 'pdf_encrypted',\n",
    "                      'n_defenses', 'n_crypto_algs', 'n_protection_profiles', 'sec_level_cat',\n",
    "                      'n_pages_cat', 'n_updates_cat', 'cert_year', 'scheme_cat']]\n",
    "\n",
    "features.category = features.category.astype('category').cat.codes\n",
    "features.scheme_cat = features.scheme_cat.astype('category').cat.codes\n",
    "\n",
    "labels = np.array(features['sec_level_cat'])\n",
    "label_names = list(sec_level_dict.keys())[1:]\n",
    "features.drop('sec_level_cat', axis=1, inplace=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state=42, stratify=labels)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RandomForest classifier / regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf.fit(train_features, train_labels)\n",
    "y_pred = rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(predictions, test_labels, normalize=True)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_names = list(features.columns)\n",
    "plot_feature_importances(importances, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_confusion_matrix(rf, x_test, y_test, normalize=None, cmap='Greens', xticks_rotation=45, display_labels=label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
