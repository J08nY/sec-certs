{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/adam/phd/projects/certificates/data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load json features into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all features and fill a dataframe with them\n",
    "feature_dict = {x: [] for x in ['category', 'scheme', 'n_updates', 'sec_level', 'sec_level_processed', 'cert_lab', 'n_pages',\n",
    "                           'cert_date', 'archived_date', 'manufacturer']}\n",
    "for key, val in data.items():\n",
    "    cert = data[key]\n",
    "    feature_dict['category'].append(cert['csv_scan'].get('cc_category', np.nan))\n",
    "    feature_dict['scheme'].append(cert['csv_scan'].get('cc_scheme', np.nan))\n",
    "    feature_dict['n_updates'].append(len(cert['csv_scan'].get('maintainance_updates', np.nan)))\n",
    "    feature_dict['sec_level'].append(cert['csv_scan'].get('cc_security_level', np.nan))\n",
    "    feature_dict['sec_level_processed'].append(cert['processed'].get('cc_security_level', np.nan))\n",
    "    feature_dict['cert_lab'].append(cert['processed'].get('cert_lab', np.nan))\n",
    "    feature_dict['cert_date'].append(cert['csv_scan'].get('cc_certification_date', np.nan))\n",
    "    feature_dict['archived_date'].append(cert['csv_scan'].get('cc_archived_date', np.nan))\n",
    "    feature_dict['manufacturer'].append(cert['processed'].get('cc_manufacturer_simple', np.nan))\n",
    "\n",
    "    meta_scan = cert.get('pdfmeta_scan') or {}\n",
    "    n_pages = meta_scan.get('pdf_number_of_pages', np.nan)\n",
    "    feature_dict['n_pages'].append(n_pages)\n",
    "df = pd.DataFrame(data=feature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map security level into ordered categories\n",
    "sec_level_dict = {'None': np.nan, 'EAL1': 0, 'EAL1+': 1, 'EAL2': 2, 'EAL2+': 3, 'EAL3': 4, 'EAL3+': 4, 'EAL4': 5, 'EAL4+': 6, 'EAL5': 7, 'EAL5+': 8, 'EAL6': 9, 'EAL6+': 10, 'EAL7': 11, 'EAL7+': 12}\n",
    "df['sec_level_cat'] = df.sec_level_processed.map(sec_level_dict)\n",
    "sec_level_median = df['sec_level_cat'].loc[df.sec_level_cat != -1].median()\n",
    "df['sec_level_cat'].fillna(sec_level_median, inplace=True)\n",
    "\n",
    "# Fill-in missing values of n_pages with median and categorize into intervals (ordered)\n",
    "n_pages_median = df.n_pages.median()\n",
    "df.n_pages.fillna(n_pages_median, inplace=True)\n",
    "\n",
    "df['n_pages_cat'] = pd.cut(df.n_pages, [0, 10, 15, 30, 40, 50, 5000], labels=[x for x in range(6)])\n",
    "df.n_pages_cat = df['n_pages_cat'].astype('int64')\n",
    "\n",
    "# Categories number of updates to intervals\n",
    "df['n_updates_cat'] = pd.cut(df.n_updates, [-1, 0, 1, 2, 3, 100], labels=[x for x in range(5)])\n",
    "df['n_updates_cat'] = df['n_updates_cat'].astype('int64')\n",
    "\n",
    "# Create year of certification feature\n",
    "df.cert_date = pd.to_datetime(df.cert_date)\n",
    "df.archived_date = pd.to_datetime(df.archived_date)\n",
    "df['cert_year'] = df.cert_date.dt.year\n",
    "\n",
    "# Drop rows that didn't yet been archived\n",
    "#df = df.loc[~df.archived_date.isnull(), :]\n",
    "\n",
    "# Select timedelta in months between cert date and archived date\n",
    "#df['n_days_valid'] = df.archived_date - df.cert_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histogram\n",
    "%matplotlib inline\n",
    "df.hist(bins=20, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show correlations between numerical features and the target feature\n",
    "df.corr()['sec_level_cat'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, ['category', 'scheme', 'n_updates_cat', 'sec_level_cat', 'n_pages_cat', 'cert_year']]\n",
    "\n",
    "features.category = features.category.astype('category').cat.codes\n",
    "features.scheme = features.scheme.astype('category').cat.codes\n",
    "#features.sec_level = features.sec_level.astype('category').cat.codes\n",
    "#features.n_days_valid = features.n_days_valid.apply(lambda x: float(x.days))\n",
    "\n",
    "labels = np.array(features['sec_level_cat']) # we can also predict sec_level for instance\n",
    "features.drop('sec_level_cat', axis=1, inplace=True)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RandomForest classifier / regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf.fit(train_features, train_labels)\n",
    "predictions = rf.predict(test_features)\n",
    "acc = accuracy_score(predictions, test_labels, normalize=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=70)\n",
    "rf.fit(train_features, train_labels)\n",
    "predictions = rf.predict(test_features)\n",
    "mae = mean_absolute_error(predictions, test_labels)\n",
    "mse = mean_squared_error(predictions, test_labels)\n",
    "print(f'MAE: {mae}\\nMSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2612814181353973,\n",
       " 0.27468679428471143,\n",
       " 0.05807405038482223,\n",
       " 0.07975754753925322,\n",
       " 0.3262001896558157]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
